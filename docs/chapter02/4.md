---
layout: page-sidenav
group: "Chapter. 2"
title: "4. Bayesian machine learning"
author: Hyungjin Chung
---

- 섹션 2.2와 2.3에서는 output으로 나오는 prediction 값 \\( y \\)가 input, 또는 feature에 의존하지 않았었다.
- Training data는 존재하고 그로부터 \\( y \\)값을 예측하거나 범위를 구하는 문제들이었다.
- 하지만 많은 practical application에서는 특정 input \\( x \\)가 존재한다. 이를 **input**, 또는 **feature**라고 한다.
- 이 경우 training data에만 의존적인 \\( p(\mathbf{y}\|\mathcal{D}) \\) 가 아니라 input data에까지 의존적인 \\( p(\mathbf{y}\|\mathbf{x}, \mathcal{D}) \\) 를 구하게 된다.
- 이를 *conditional* probability distribution이라고 하고, 이 때 training data \\( \mathcal{D} \\) 는 전과 같이 \\( \mathbf{x} \\) 값만 존재하는 것이 아니라 input과 output이 pair로 존재한다.
- \\( \mathcal{D} = \{ (\mathbf{x}, \mathbf{y}) : n = 1 : N \} \\)로 존재하며, 
    - \\( \mathbf{y} \\)가 class label과 같은 **low-dimensional data**일 때 **discriminative model**으로 볼 수 있고,
    - \\( \mathbf{y}} \\)가 이미지와 같은 **high-dimensional data**일 때 **conditional generative model**으로 볼 수 있다.
- 이와 같이 prediction이 input에 dependent해지는 상황에서, 우리가 예측하고자 하는 hypothesis \\( h \\)는 보통 real-valued parameter \\( \mathbf{\theta} \in \mathbb{R}^K \\) 인 경우가 많다.
    - 가장 간단한 linear regression부터 현대에 쓰이는 neural network까지 모두 이렇다.
    - 이를 식으로 표현하자면 아래와 같다.

$$
p(\mathbf{y}|\mathbf{x}, \mathbf{\theta}) = p(\mathbf{y}|f(\mathbf{x};\mathbf{\theta})) \qquad{(2.28)}
$$

- 위 식에서 \\( f(\mathbf{x};\mathbf{\theta}) \\)는 input을 output distribution의 파라미터로 매핑시키는 역할을 한다.
- 결국 식 (2.28)을 완전히 표현하려면 두 가지가 필요하다.
    1. Output probability distribution \\( p \\)
    2. Form of the predictor \\( f \\)
- 일단 1번부터 알아보도록 하자.

## 1. Fully Bayesian approach

- 앞선 내용의 복습이다. Bayesian approach로 conditional predictive model을 만들기 위해선 우선 파라미터에 대한 posterior를 구한 후,
$$
p(\mathbf{\theta}|\mathcal{D}) = \frac{p(\mathbf{\theta}) p(\mathcal{D}|\mathbf{\theta})}{p(\mathcal{D})} \qquad{(2.29)}
$$
- 구해진 posterior를 이용해 posterior predictive를 계산할 수 있다.
$$
p(\mathbf{y}|\mathbf{x}, \mathcal{D}) = \int p(\mathbf{y}|\mathbf{x}, \mathbf{\theta}) p(\mathbf{\theta}|\mathcal{D}) d\mathbf{\theta} \qquad{(2.30)}
$$

## 2. Plug-in approximation

- 많은 경우에 posterior predictive를 위한 적분이 매우 costly할 수 있으므로, posterior를 **point estimate**하는 것이 더 practical할 수 있다.

1. MLE
    - MLE를 구하기 위해선 likelihood를 최대화해야하기 때문에
    $$
    \hat{\theta_{\textrm{mle}}} = 
    $$


    